{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w3DgkwZeZfD"
      },
      "source": [
        "Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBKtssViWOpH"
      },
      "source": [
        "!pip install -U -q PyDrive \r\n",
        "  \r\n",
        "from pydrive.auth import GoogleAuth \r\n",
        "from pydrive.drive import GoogleDrive \r\n",
        "from google.colab import auth \r\n",
        "from oauth2client.client import GoogleCredentials \r\n",
        "  \r\n",
        "  \r\n",
        "# Authenticate and create the PyDrive client. \r\n",
        "auth.authenticate_user() \r\n",
        "gauth = GoogleAuth() \r\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "b8JBlK6WaNai",
        "outputId": "ed4b1526-f3b8-42df-c477-d28454398561"
      },
      "source": [
        "link = 'https://drive.google.com/file/d/1YFQduaJ57Lx0EvhStxafhSXKM-3jbIbe/view?usp=sharing'\r\n",
        "  \r\n",
        "import pandas as pd \r\n",
        "  \r\n",
        "# to get the id part of the file \r\n",
        "id = link.split(\"/\")[-2] \r\n",
        "  \r\n",
        "downloaded = drive.CreateFile({'id':id})  \r\n",
        "downloaded.GetContentFile('IMDB Dataset.csv')   \r\n",
        "# Importing the dataset  \r\n",
        "df = pd.read_csv('IMDB Dataset.csv') \r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUELSgGcbRSW"
      },
      "source": [
        "# Conversion to the text file\r\n",
        "df.review.to_csv('reviews.txt', sep=\" \", header=False)\r\n",
        "df.sentiment.to_csv('sentiment.txt', sep=\" \", header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-_Zy38cdhL"
      },
      "source": [
        "# Importing text file\r\n",
        "with open(\"reviews.txt\") as f:\r\n",
        "    reviews = f.read()\r\n",
        "    \r\n",
        "with open(\"sentiment.txt\") as f:\r\n",
        "    sentiment = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrbIcO6Hemnj"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZbpsPa6dAmE"
      },
      "source": [
        "from string import punctuation\r\n",
        "\r\n",
        "def preprocess(text):\r\n",
        "    text = text.lower()\r\n",
        "    # Omitting punctuation marks from the text file \r\n",
        "    text = \"\".join([letter for letter in text if letter not in punctuation])\r\n",
        "    # collecting all the reviews\r\n",
        "    universe = text.split(\"\\n\")\r\n",
        "    text = \"\".join(text)\r\n",
        "    # collecting all the words\r\n",
        "    corpus = text.split()\r\n",
        "    \r\n",
        "    return universe, corpus\r\n",
        "\r\n",
        "\r\n",
        "universe, corpus = preprocess(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehSNGSSesmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136d0b71-1407-47e6-c22e-e62dbd7edf3f"
      },
      "source": [
        "universe[0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with mebr br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordbr br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awaybr br i would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side',\n",
              " '1 a wonderful little production br br the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece br br the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life br br the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done',\n",
              " '2 i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovebr br this was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanbr br this may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe73MqVzvx-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4461c4b9-c112-48ee-852d-1db5deb2992e"
      },
      "source": [
        "corpus[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'other',\n",
              " 'reviewers',\n",
              " 'has',\n",
              " 'mentioned',\n",
              " 'that',\n",
              " 'after']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0iv1w0bCVwh"
      },
      "source": [
        "Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz2EDhUTxMjK"
      },
      "source": [
        "from collections import Counter\r\n",
        "word_count = Counter(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psosGfX38wuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f95ff6-3307-49a3-8ed8-a9b085eb6f90"
      },
      "source": [
        "vocab = sorted(word_count, key=word_count.get, reverse=True)\r\n",
        "vocab[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'and', 'a', 'of', 'to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02MD4V2V-UVN"
      },
      "source": [
        "vocab_to_int = {word: idx+1 for idx, word in enumerate(vocab)}\r\n",
        "int_to_vocab = {idx: word for idx, word in vocab_to_int.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9QMAgaj9Iiv"
      },
      "source": [
        "encoded_reviews = [[vocab_to_int[word] for word in review.split()] for review in universe]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F63QRDbHLfBV"
      },
      "source": [
        "import re\r\n",
        "labels=sentiment.split(\"\\n\")\r\n",
        "labels = \"\".join([re.sub(\"\\d\", \"\", label) for label in labels])\r\n",
        "labels =labels.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRsKzIgCAnsj"
      },
      "source": [
        "encoded_labels=[1 if label == \"positive\" else 0 for label in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWTzyU9zCsuT"
      },
      "source": [
        "Analysis of Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO6nQw9vCzzp"
      },
      "source": [
        "Analysis of Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jU2a9lJWmKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83b69ca-e02a-486d-d2ea-5ea0796e40a3"
      },
      "source": [
        "word_len=[len(x) for x in encoded_reviews]\r\n",
        "pd.Series(word_len).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    50001.000000\n",
              "mean       231.253615\n",
              "std        170.665314\n",
              "min          0.000000\n",
              "25%        127.000000\n",
              "50%        173.000000\n",
              "75%        281.000000\n",
              "max       2470.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmz_SmCDdM_o"
      },
      "source": [
        "import numpy as np\r\n",
        "pad_max=np.quantile(word_len, 0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNEgD1bbcueu"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgCfKx6ZdFi9"
      },
      "source": [
        "encoded_labels = np.array( [label for idx, label in enumerate(encoded_labels) if len(encoded_reviews[idx]) > 0] )\r\n",
        "encoded_reviews = [review for review in encoded_reviews if len(review) > 0]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Jr5nrPdcpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b6e25b-f118-4db8-d842-bd0efd1b32a5"
      },
      "source": [
        "print(len(encoded_reviews))\r\n",
        "print(len(encoded_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkQW2lJReKZQ"
      },
      "source": [
        "Padding\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHatG4yhdk2A"
      },
      "source": [
        "def pad_text(encoded_reviews, seq_length):\r\n",
        "    \r\n",
        "    reviews = []\r\n",
        "    \r\n",
        "    for review in encoded_reviews:\r\n",
        "        if len(review) >= seq_length:\r\n",
        "            reviews.append(review[:seq_length])\r\n",
        "        else:\r\n",
        "            reviews.append([0]*(seq_length-len(review)) + review)\r\n",
        "        \r\n",
        "    return np.array(reviews)\r\n",
        "padded_reviews = pad_text(encoded_reviews, seq_length = 900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AlpTACieV52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556cd56c-f04b-462f-8601-0941e98fe3a0"
      },
      "source": [
        "padded_reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   122,  4020,   501],\n",
              "       [    0,     0,     0, ...,  1900,    73,   223],\n",
              "       [    0,     0,     0, ...,    64,    15,   333],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 23659,     2,  6059],\n",
              "       [    0,     0,     0, ...,    68,   711,    42],\n",
              "       [    0,     0,     0, ...,   782,    10,    17]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAcciYgBeeIq"
      },
      "source": [
        "Train-test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ztGh-IebEH"
      },
      "source": [
        "train_ratio = 0.8\r\n",
        "valid_ratio = (1 - train_ratio)/2\r\n",
        "total = padded_reviews.shape[0]\r\n",
        "train_cutoff = int(total * train_ratio)\r\n",
        "valid_cutoff = int(total * (1 - valid_ratio))\r\n",
        "\r\n",
        "train_x, train_y = padded_reviews[:train_cutoff], encoded_labels[:train_cutoff]\r\n",
        "valid_x, valid_y = padded_reviews[train_cutoff : valid_cutoff], encoded_labels[train_cutoff : valid_cutoff]\r\n",
        "test_x, test_y = padded_reviews[valid_cutoff:], encoded_labels[valid_cutoff:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqLcXfnFek7F"
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "# create Tensor datasets\r\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\r\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\r\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\r\n",
        "# dataloaders\r\n",
        "batch_size = 50\r\n",
        "# make sure to SHUFFLE your data\r\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\r\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\r\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ysUINieu7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551b77d7-b8a9-48d3-d061-70b75ee412b6"
      },
      "source": [
        "train_x,train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   0,    0,    0, ...,  122, 4020,  501],\n",
              "        [   0,    0,    0, ..., 1900,   73,  223],\n",
              "        [   0,    0,    0, ...,   64,   15,  333],\n",
              "        ...,\n",
              "        [   0,    0,    0, ...,    5,  129,  120],\n",
              "        [   0,    0,    0, ...,  284,   59,  153],\n",
              "        [   0,    0,    0, ...,   59,   15,   10]]),\n",
              " array([1, 1, 1, ..., 1, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUWr0z4ZezFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b00e9d-a254-4e9b-fa4c-0316c9fd5e78"
      },
      "source": [
        "valid_x, valid_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[     0,      0,      0, ...,      5,    128,   1601],\n",
              "        [     0,      0,      0, ...,    162,    111,   3790],\n",
              "        [     0,      0,      0, ...,      9,     13,    990],\n",
              "        ...,\n",
              "        [     0,      0,      0, ...,   1827,   1320,     22],\n",
              "        [     0,      0,      0, ..., 215947,     12,   1979],\n",
              "        [     0,      0,      0, ...,      4,      1,    188]]),\n",
              " array([0, 0, 0, ..., 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsXlpMw0e1-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba32269-f311-417a-9205-1621ad575f23"
      },
      "source": [
        "test_x, test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[     0,      0,      0, ...,     53, 215950,    120],\n",
              "        [     0,      0,      0, ...,   7515,     16,   5322],\n",
              "        [     0,      0,      0, ...,     70,     10,    625],\n",
              "        ...,\n",
              "        [     0,      0,      0, ...,  23659,      2,   6059],\n",
              "        [     0,      0,      0, ...,     68,    711,     42],\n",
              "        [     0,      0,      0, ...,    782,     10,     17]]),\n",
              " array([1, 1, 0, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTgTdgttfG1k"
      },
      "source": [
        "Model designing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N5rSpTEmBK5"
      },
      "source": [
        "from torch import nn\r\n",
        "\r\n",
        "class SentimentLSTM(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.5):\r\n",
        "        super().__init__()\r\n",
        "        # params: \"n_\" means dimension\r\n",
        "        self.n_vocab = n_vocab     # number of unique words in vocabulary\r\n",
        "        self.n_layers = n_layers   # number of LSTM layers \r\n",
        "        self.n_hidden = n_hidden   # number of hidden nodes in LSTM\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\r\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\r\n",
        "        self.dropout = nn.Dropout(drop_p)\r\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        \r\n",
        "        \r\n",
        "    def forward (self, input_words):\r\n",
        "                                             # INPUT   :  (batch_size, seq_length)\r\n",
        "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\r\n",
        "        lstm_out, h = self.lstm(embedded_words)         # (batch_size, seq_length, n_hidden)\r\n",
        "        lstm_out = self.dropout(lstm_out)\r\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden) # (batch_size*seq_length, n_hidden)\r\n",
        "        fc_out = self.fc(lstm_out)                      # (batch_size*seq_length, n_output)\r\n",
        "        sigmoid_out = self.sigmoid(fc_out)              # (batch_size*seq_length, n_output)\r\n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)  # (batch_size, seq_length*n_output)\r\n",
        "        \r\n",
        "        # extract the output of ONLY the LAST output of the LAST element of the sequence\r\n",
        "        sigmoid_last = sigmoid_out[:, -1]               # (batch_size, 1)\r\n",
        "        \r\n",
        "        return sigmoid_last, h\r\n",
        "    \r\n",
        "    \r\n",
        "    def init_hidden (self, batch_size):  # initialize hidden weights (h,c) to 0\r\n",
        "        \r\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "        weights = next(self.parameters()).data\r\n",
        "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\r\n",
        "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\r\n",
        "        \r\n",
        "        return h\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ-wZqSdfFFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233c0c75-951e-4083-ee10-a837f1b1ed0b"
      },
      "source": [
        "n_vocab = len(vocab_to_int)\r\n",
        "n_embed = 50\r\n",
        "n_hidden = 32\r\n",
        "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\r\n",
        "n_layers = 2\r\n",
        "\r\n",
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)\r\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(230647, 50)\n",
            "  (lstm): LSTM(50, 32, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeRWaGq-fVbH"
      },
      "source": [
        "Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bREDkVjufY_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40b6280-9f2c-4af9-9c2b-99cb575b5d46"
      },
      "source": [
        "from torch import optim\r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print_every = 50\r\n",
        "step = 0\r\n",
        "n_epochs = 2  # validation loss increases from ~ epoch 3 or 4\r\n",
        "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "for epoch in range(n_epochs):\r\n",
        "    h = net.init_hidden(batch_size)\r\n",
        "    \r\n",
        "    for inputs, labels in train_loader:\r\n",
        "        step += 1\r\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "        \r\n",
        "        # making requires_grad = False for the latest set of h\r\n",
        "        h = tuple([each.data for each in h])   \r\n",
        "        \r\n",
        "        net.zero_grad()\r\n",
        "        output, h = net(inputs)\r\n",
        "        loss = criterion(output.squeeze(), labels.float())\r\n",
        "        loss.backward()\r\n",
        "        nn.utils.clip_grad_norm(net.parameters(), clip)\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        if (step % print_every) == 0:            \r\n",
        "            \r\n",
        "            net.eval()\r\n",
        "            valid_losses = []\r\n",
        "            v_h = net.init_hidden(batch_size)\r\n",
        "            \r\n",
        "            for v_inputs, v_labels in valid_loader:\r\n",
        "                v_inputs, v_labels = inputs.to(device), labels.to(device)\r\n",
        "        \r\n",
        "                v_h = tuple([each.data for each in v_h])\r\n",
        "                \r\n",
        "                v_output, v_h = net(v_inputs)\r\n",
        "                v_loss = criterion(v_output.squeeze(), v_labels.float())\r\n",
        "                valid_losses.append(v_loss.item())\r\n",
        "\r\n",
        "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\r\n",
        "                  \"Step: {}\".format(step),\r\n",
        "                  \"Training Loss: {:.4f}\".format(loss.item()),\r\n",
        "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\r\n",
        "            net.train()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2 Step: 50 Training Loss: 0.7233 Validation Loss: 0.6801\n",
            "Epoch: 1/2 Step: 100 Training Loss: 0.6884 Validation Loss: 0.6960\n",
            "Epoch: 1/2 Step: 150 Training Loss: 0.6955 Validation Loss: 0.6878\n",
            "Epoch: 1/2 Step: 200 Training Loss: 0.7069 Validation Loss: 0.6816\n",
            "Epoch: 1/2 Step: 250 Training Loss: 0.7152 Validation Loss: 0.6825\n",
            "Epoch: 1/2 Step: 300 Training Loss: 0.7147 Validation Loss: 0.6993\n",
            "Epoch: 1/2 Step: 350 Training Loss: 0.6762 Validation Loss: 0.6730\n",
            "Epoch: 1/2 Step: 400 Training Loss: 0.6935 Validation Loss: 0.6778\n",
            "Epoch: 1/2 Step: 450 Training Loss: 0.6922 Validation Loss: 0.6914\n",
            "Epoch: 1/2 Step: 500 Training Loss: 0.6700 Validation Loss: 0.6768\n",
            "Epoch: 1/2 Step: 550 Training Loss: 0.6888 Validation Loss: 0.6867\n",
            "Epoch: 1/2 Step: 600 Training Loss: 0.6956 Validation Loss: 0.6895\n",
            "Epoch: 1/2 Step: 650 Training Loss: 0.6882 Validation Loss: 0.6975\n",
            "Epoch: 1/2 Step: 700 Training Loss: 0.6982 Validation Loss: 0.6884\n",
            "Epoch: 1/2 Step: 750 Training Loss: 0.6981 Validation Loss: 0.6948\n",
            "Epoch: 1/2 Step: 800 Training Loss: 0.6746 Validation Loss: 0.6818\n",
            "Epoch: 2/2 Step: 850 Training Loss: 0.6887 Validation Loss: 0.6842\n",
            "Epoch: 2/2 Step: 900 Training Loss: 0.7035 Validation Loss: 0.6946\n",
            "Epoch: 2/2 Step: 950 Training Loss: 0.7191 Validation Loss: 0.7139\n",
            "Epoch: 2/2 Step: 1000 Training Loss: 0.7094 Validation Loss: 0.6830\n",
            "Epoch: 2/2 Step: 1050 Training Loss: 0.6854 Validation Loss: 0.7016\n",
            "Epoch: 2/2 Step: 1100 Training Loss: 0.6834 Validation Loss: 0.6878\n",
            "Epoch: 2/2 Step: 1150 Training Loss: 0.7444 Validation Loss: 0.6936\n",
            "Epoch: 2/2 Step: 1200 Training Loss: 0.6749 Validation Loss: 0.6884\n",
            "Epoch: 2/2 Step: 1250 Training Loss: 0.6986 Validation Loss: 0.6843\n",
            "Epoch: 2/2 Step: 1300 Training Loss: 0.6639 Validation Loss: 0.6898\n",
            "Epoch: 2/2 Step: 1350 Training Loss: 0.6853 Validation Loss: 0.6869\n",
            "Epoch: 2/2 Step: 1400 Training Loss: 0.6869 Validation Loss: 0.6905\n",
            "Epoch: 2/2 Step: 1450 Training Loss: 0.6913 Validation Loss: 0.6928\n",
            "Epoch: 2/2 Step: 1500 Training Loss: 0.6921 Validation Loss: 0.6933\n",
            "Epoch: 2/2 Step: 1550 Training Loss: 0.6884 Validation Loss: 0.6890\n",
            "Epoch: 2/2 Step: 1600 Training Loss: 0.7076 Validation Loss: 0.7001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxpdZF95mQgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "c421207f-7b81-458a-850b-6a45618cee3f"
      },
      "source": [
        "net.eval()\r\n",
        "test_losses = []\r\n",
        "num_correct = 0\r\n",
        "h = net.init_hidden(batch_size)\r\n",
        "\r\n",
        "for inputs, labels in test_loader:\r\n",
        "    h = tuple([each.data for each in h])\r\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "    test_output, h = net(inputs)\r\n",
        "    loss = criterion(test_output.squeeze(), labels.float())\r\n",
        "    test_losses.append(loss.item())\r\n",
        "    \r\n",
        "    preds = torch.round(test_output.squeeze())\r\n",
        "    correct_tensor = preds.eq(labels.float().view_as(preds))\r\n",
        "    correct = np.squeeze(correct_tensor.numpy())\r\n",
        "    num_correct += np.sum(correct)\r\n",
        "    \r\n",
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\r\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-cf52374275de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-65bf0e65bb6b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_words)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                              \u001b[0;31m# INPUT   :  (batch_size, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0membedded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# (batch_size, seq_length, n_embed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_words\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# (batch_size, seq_length, n_hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m         return F.embedding(\n\u001b[1;32m    146\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym-2GNqXGU3W"
      },
      "source": [
        "def predict(net, review, seq_length = 200):\r\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "    \r\n",
        "    words = preprocess(review)\r\n",
        "    encoded_words = [vocab_to_int[word] for word in words]\r\n",
        "    padded_words = pad_text([encoded_words], seq_length)\r\n",
        "    padded_words = torch.from_numpy(padded_words).to(device)\r\n",
        "    \r\n",
        "    if(len(padded_words) == 0):\r\n",
        "        \"Your review must contain at least 1 word!\"\r\n",
        "        return None\r\n",
        "    \r\n",
        "    net.eval()\r\n",
        "    h = net.init_hidden(1)\r\n",
        "    output, h = net(padded_words, h)\r\n",
        "    pred = torch.round(output.squeeze())\r\n",
        "    msg = \"This is a positive review.\" if pred == 0 else \"This is a negative review.\"\r\n",
        "    \r\n",
        "    return msg"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}